{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtBoroqIfKLv"
   },
   "source": [
    "## Validation of YOLOv8x GridSearch Models\n",
    "#### File Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7SvgqqSfICB"
   },
   "outputs": [],
   "source": [
    "# function for calculating mAP50 for all classes, priority classes and lower-priority classes\n",
    "def calc_map50_class_groups(metrics_object):\n",
    "    priority_classes = [metrics_object.box.ap50[4], metrics_object.box.ap50[5], metrics_object.box.ap50[6], metrics_object.box.ap50[7]]\n",
    "    lower_priority_classes = [metrics_object.box.ap50[2], metrics_object.box.ap50[8], metrics_object.box.ap50[1],\n",
    "                              metrics_object.box.ap50[3], metrics_object.box.ap50[0]]\n",
    "    priority_class_map50 = round(sum(priority_classes)/len(priority_classes),3)\n",
    "    lower_priority_class_map50 = round(sum(lower_priority_classes)/len(lower_priority_classes),3)\n",
    "    print(f\"mAP50 for all classes is {round(metrics.box.map50,3)}\")\n",
    "    print(f\"mAP50 for priority classes is {priority_class_map50}\")\n",
    "    print(f\"mAP50 for lower-priority classes is {lower_priority_class_map50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmJw6w_Le6w2"
   },
   "outputs": [],
   "source": [
    "# solves occasional error with Linux commands and encoding\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjuAv6ELe8Up",
    "outputId": "712de84b-a206-48f4-f226-6314da4290c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive for saving runs and model files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYchVPa7e90U",
    "outputId": "f5d2b13a-2b15-48a2-fe29-4f16ee32f0fd"
   },
   "outputs": [],
   "source": [
    "# copy dataset from google drive\n",
    "!unzip /content/drive/MyDrive/UniStuff/Dissertation/Dataset_zips/WSP-9.zip -d /content/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfAH7c_NfAin",
    "outputId": "de9ba603-705f-4661-cae7-86d9a3a249c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Setup complete âœ… (12 CPUs, 53.0 GB RAM, 35.9/78.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# install and import ultralytics\n",
    "\n",
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbZ1awbIfPtU"
   },
   "source": [
    "### Validation\n",
    "#### Learning Rate = 0.1\n",
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCPujpwqfZv_",
    "outputId": "ffce4bca-a336-492b-fd09-dfe4e129a7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 109MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 1315.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/WSP-9/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:15<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011       0.79       0.74      0.782      0.598\n",
      "           Articulated         68        113      0.832      0.841      0.861      0.644\n",
      "                   Bus         56         89      0.919      0.775       0.85      0.694\n",
      "                   Car        154       1251      0.868      0.891      0.942      0.625\n",
      "                 Coach         24         29      0.915      0.552      0.722      0.624\n",
      "                   LGV        180        273      0.757      0.762      0.813       0.62\n",
      "          Rigid 2 Axle        123        168       0.79      0.671      0.773      0.556\n",
      "          Rigid 3 Axle         17         17      0.486      0.529      0.476      0.402\n",
      "          Rigid 4 Axle         41         42      0.815      0.952      0.942      0.738\n",
      "                  Taxi         20         29      0.724       0.69      0.658      0.474\n",
      "Speed: 0.7ms preprocess, 23.8ms inference, 0.0ms loss, 10.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "mAP50 for all classes is 0.782\n",
      "mAP50 for priority classes is 0.751\n",
      "mAP50 for lower-priority classes is 0.807\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Guz38Zauf-FW",
    "outputId": "818ab02a-a4fc-4bd0-88a6-9951d99645d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.764      0.684      0.741       0.56\n",
      "           Articulated         68        113      0.798      0.732      0.792      0.591\n",
      "                   Bus         56         89      0.914      0.718      0.815      0.662\n",
      "                   Car        154       1251      0.884      0.865      0.927      0.609\n",
      "                 Coach         24         29      0.811      0.621      0.695      0.579\n",
      "                   LGV        180        273      0.837      0.736      0.803      0.607\n",
      "          Rigid 2 Axle        123        168      0.772      0.536      0.693      0.473\n",
      "          Rigid 3 Axle         17         17      0.273      0.471      0.358        0.3\n",
      "          Rigid 4 Axle         41         42      0.795      0.952      0.933      0.755\n",
      "                  Taxi         20         29      0.792      0.524      0.655      0.467\n",
      "Speed: 0.7ms preprocess, 23.8ms inference, 0.0ms loss, 8.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "mAP50 for all classes is 0.741\n",
      "mAP50 for priority classes is 0.697\n",
      "mAP50 for lower-priority classes is 0.777\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8OVqsaAf-ZB",
    "outputId": "523ce405-6c5a-489a-e0b5-ccf753868a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.432      0.426      0.418      0.228\n",
      "           Articulated         68        113      0.367      0.487      0.437      0.207\n",
      "                   Bus         56         89      0.543      0.472      0.486      0.277\n",
      "                   Car        154       1251      0.625      0.861      0.823      0.401\n",
      "                 Coach         24         29      0.244      0.123      0.139     0.0745\n",
      "                   LGV        180        273      0.411      0.637      0.542       0.29\n",
      "          Rigid 2 Axle        123        168      0.347      0.298       0.33      0.168\n",
      "          Rigid 3 Axle         17         17       0.68      0.294      0.379      0.263\n",
      "          Rigid 4 Axle         41         42      0.401      0.643       0.49      0.289\n",
      "                  Taxi         20         29      0.274     0.0189      0.136     0.0829\n",
      "Speed: 0.8ms preprocess, 25.5ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "mAP50 for all classes is 0.418\n",
      "mAP50 for priority classes is 0.435\n",
      "mAP50 for lower-priority classes is 0.404\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywviOVwflQ9"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ix80uszufnIY",
    "outputId": "88edfeca-e7c5-4503-db33-03e5d78c23c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.728      0.594      0.661      0.479\n",
      "           Articulated         68        113      0.725      0.629      0.735       0.52\n",
      "                   Bus         56         89      0.801      0.719      0.783      0.617\n",
      "                   Car        154       1251      0.834      0.886      0.918      0.588\n",
      "                 Coach         24         29      0.818      0.448      0.568      0.476\n",
      "                   LGV        180        273      0.745      0.681      0.745      0.548\n",
      "          Rigid 2 Axle        123        168      0.758      0.387       0.62      0.419\n",
      "          Rigid 3 Axle         17         17      0.844      0.294      0.368       0.28\n",
      "          Rigid 4 Axle         41         42      0.595      0.952      0.792      0.595\n",
      "                  Taxi         20         29      0.437      0.345      0.423      0.267\n",
      "Speed: 0.7ms preprocess, 24.1ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "mAP50 for all classes is 0.661\n",
      "mAP50 for priority classes is 0.631\n",
      "mAP50 for lower-priority classes is 0.686\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frTVFnKEg-s0",
    "outputId": "1f1b245f-5b22-43c7-9a42-81156bf25c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.716      0.599      0.667      0.482\n",
      "           Articulated         68        113      0.697      0.593        0.7      0.478\n",
      "                   Bus         56         89      0.793      0.708       0.79      0.591\n",
      "                   Car        154       1251      0.863      0.858      0.905       0.58\n",
      "                 Coach         24         29      0.759      0.542      0.602      0.504\n",
      "                   LGV        180        273      0.723      0.674      0.708      0.505\n",
      "          Rigid 2 Axle        123        168      0.673      0.375      0.582      0.392\n",
      "          Rigid 3 Axle         17         17      0.664      0.412      0.464      0.374\n",
      "          Rigid 4 Axle         41         42      0.701      0.952      0.904      0.674\n",
      "                  Taxi         20         29      0.573      0.278       0.35      0.241\n",
      "Speed: 0.7ms preprocess, 24.2ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
      "mAP50 for all classes is 0.667\n",
      "mAP50 for priority classes is 0.664\n",
      "mAP50 for lower-priority classes is 0.67\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYKKpm6sg--W",
    "outputId": "ef363ac9-b917-48a2-c0ef-41b6eb9252e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.515      0.208      0.185     0.0704\n",
      "           Articulated         68        113          1     0.0241     0.0839     0.0227\n",
      "                   Bus         56         89       0.33      0.326      0.172     0.0758\n",
      "                   Car        154       1251      0.437      0.766      0.655      0.253\n",
      "                 Coach         24         29          0          0     0.0497     0.0153\n",
      "                   LGV        180        273      0.378      0.366      0.291      0.109\n",
      "          Rigid 2 Axle        123        168      0.221     0.0357       0.11     0.0329\n",
      "          Rigid 3 Axle         17         17          1          0     0.0302     0.0132\n",
      "          Rigid 4 Axle         41         42      0.269      0.357      0.243      0.095\n",
      "                  Taxi         20         29          1          0     0.0303      0.016\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
      "mAP50 for all classes is 0.185\n",
      "mAP50 for priority classes is 0.169\n",
      "mAP50 for lower-priority classes is 0.198\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-qvWlrJfm3L"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQBMB8BDfqGE",
    "outputId": "17eca543-0fab-4871-b0e9-5069ba17911b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 21.6MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 1312.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/WSP-9/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.395      0.202      0.153     0.0917\n",
      "           Articulated         68        113      0.202     0.0531     0.0612     0.0309\n",
      "                   Bus         56         89      0.175      0.236      0.111     0.0686\n",
      "                   Car        154       1251      0.586       0.73      0.692      0.405\n",
      "                 Coach         24         29      0.116      0.069     0.0369     0.0242\n",
      "                   LGV        180        273      0.189      0.484      0.239      0.154\n",
      "          Rigid 2 Axle        123        168      0.224      0.155      0.128     0.0734\n",
      "          Rigid 3 Axle         17         17          1          0     0.0354     0.0227\n",
      "          Rigid 4 Axle         41         42     0.0623     0.0952     0.0516     0.0343\n",
      "                  Taxi         20         29          1          0     0.0183     0.0117\n",
      "Speed: 0.7ms preprocess, 26.6ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "mAP50 for all classes is 0.153\n",
      "mAP50 for priority classes is 0.113\n",
      "mAP50 for lower-priority classes is 0.184\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OM4zLxyIhC21",
    "outputId": "f9222d15-e0d3-497b-8fa7-fb8e30143e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.259      0.199      0.167     0.0953\n",
      "           Articulated         68        113      0.143     0.0619     0.0574     0.0255\n",
      "                   Bus         56         89      0.102     0.0337      0.105     0.0573\n",
      "                   Car        154       1251      0.398      0.785      0.669      0.384\n",
      "                 Coach         24         29          0          0      0.109     0.0531\n",
      "                   LGV        180        273      0.214      0.418      0.275       0.16\n",
      "          Rigid 2 Axle        123        168        0.3      0.174      0.133     0.0813\n",
      "          Rigid 3 Axle         17         17     0.0879     0.0588     0.0392     0.0253\n",
      "          Rigid 4 Axle         41         42     0.0822      0.262     0.0959     0.0611\n",
      "                  Taxi         20         29          1          0      0.019    0.00979\n",
      "Speed: 0.7ms preprocess, 23.9ms inference, 0.0ms loss, 7.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "mAP50 for all classes is 0.167\n",
      "mAP50 for priority classes is 0.136\n",
      "mAP50 for lower-priority classes is 0.192\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Th3Au-UEhDGZ",
    "outputId": "00b3ad78-e585-4c04-9dc3-0ba830a41703"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:12<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011    0.00306      0.162     0.0119    0.00373\n",
      "           Articulated         68        113    0.00118     0.0708    0.00159   0.000779\n",
      "                   Bus         56         89    0.00145      0.449     0.0617     0.0164\n",
      "                   Car        154       1251    0.00848      0.314    0.00828    0.00287\n",
      "                 Coach         24         29    0.00841      0.379     0.0243    0.00822\n",
      "                   LGV        180        273    0.00184      0.158    0.00471    0.00203\n",
      "          Rigid 2 Axle        123        168    0.00615     0.0833    0.00631    0.00328\n",
      "          Rigid 3 Axle         17         17          0          0          0          0\n",
      "          Rigid 4 Axle         41         42          0          0          0          0\n",
      "                  Taxi         20         29          0          0          0          0\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "mAP50 for all classes is 0.012\n",
      "mAP50 for priority classes is 0.003\n",
      "mAP50 for lower-priority classes is 0.019\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.1/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkiaJx2JfaML"
   },
   "source": [
    "#### Learning Rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aisTf3CniPlh"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQpv8zBXfDBs",
    "outputId": "b366a386-bb13-4d8b-8055-018dc32d4f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.826       0.73      0.817       0.65\n",
      "           Articulated         68        113      0.736      0.788      0.838      0.671\n",
      "                   Bus         56         89      0.868      0.787      0.839      0.718\n",
      "                   Car        154       1251      0.894      0.879      0.942      0.637\n",
      "                 Coach         24         29      0.885      0.552      0.722      0.621\n",
      "                   LGV        180        273      0.817      0.734      0.826      0.634\n",
      "          Rigid 2 Axle        123        168      0.838      0.614      0.823      0.618\n",
      "          Rigid 3 Axle         17         17       0.61      0.588      0.636      0.545\n",
      "          Rigid 4 Axle         41         42      0.943      0.976      0.983      0.836\n",
      "                  Taxi         20         29      0.848      0.655      0.741       0.57\n",
      "Speed: 0.7ms preprocess, 24.3ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "mAP50 for all classes is 0.817\n",
      "mAP50 for priority classes is 0.817\n",
      "mAP50 for lower-priority classes is 0.817\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78QUSyiziU4P",
    "outputId": "6721065b-b13d-4cf8-a4da-e95c260a195e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.852      0.709      0.792      0.631\n",
      "           Articulated         68        113      0.778      0.752      0.811      0.661\n",
      "                   Bus         56         89      0.933      0.781      0.856       0.74\n",
      "                   Car        154       1251      0.902       0.87      0.932      0.627\n",
      "                 Coach         24         29       0.95      0.657      0.802      0.692\n",
      "                   LGV        180        273      0.833      0.752      0.822      0.638\n",
      "          Rigid 2 Axle        123        168      0.785      0.565      0.747      0.556\n",
      "          Rigid 3 Axle         17         17       0.65      0.471      0.496       0.43\n",
      "          Rigid 4 Axle         41         42      0.948      0.976      0.972      0.807\n",
      "                  Taxi         20         29      0.886      0.552      0.685      0.529\n",
      "Speed: 0.7ms preprocess, 24.6ms inference, 0.0ms loss, 8.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n",
      "mAP50 for all classes is 0.792\n",
      "mAP50 for priority classes is 0.759\n",
      "mAP50 for lower-priority classes is 0.817\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6efVqPSpiVIt",
    "outputId": "d1814c43-6f57-4e55-a4cd-71632b5846ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.671      0.605      0.687      0.474\n",
      "           Articulated         68        113      0.627      0.726      0.749      0.523\n",
      "                   Bus         56         89      0.767      0.674      0.754      0.554\n",
      "                   Car        154       1251      0.763      0.905      0.905      0.535\n",
      "                 Coach         24         29      0.689      0.414      0.556      0.421\n",
      "                   LGV        180        273      0.646      0.708      0.736      0.498\n",
      "          Rigid 2 Axle        123        168      0.673      0.476       0.64       0.41\n",
      "          Rigid 3 Axle         17         17      0.587      0.471      0.606      0.464\n",
      "          Rigid 4 Axle         41         42      0.692      0.833      0.821       0.58\n",
      "                  Taxi         20         29      0.592      0.241      0.416      0.283\n",
      "Speed: 0.7ms preprocess, 24.6ms inference, 0.0ms loss, 7.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
      "mAP50 for all classes is 0.687\n",
      "mAP50 for priority classes is 0.701\n",
      "mAP50 for lower-priority classes is 0.676\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfyCsO-2iRvJ"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkMjXULViUm1",
    "outputId": "febed69b-7019-4ae0-8800-9478fe2d84c2"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.809      0.763      0.822      0.653\n",
      "           Articulated         68        113      0.802      0.825      0.849      0.669\n",
      "                   Bus         56         89       0.85      0.809      0.878      0.735\n",
      "                   Car        154       1251      0.872      0.887      0.934      0.629\n",
      "                 Coach         24         29      0.944      0.583      0.745       0.67\n",
      "                   LGV        180        273      0.811       0.78      0.831      0.646\n",
      "          Rigid 2 Axle        123        168      0.787      0.637      0.803      0.602\n",
      "          Rigid 3 Axle         17         17      0.589      0.647      0.677      0.568\n",
      "          Rigid 4 Axle         41         42      0.889      0.976       0.98      0.811\n",
      "                  Taxi         20         29      0.733      0.724      0.706      0.546\n",
      "Speed: 0.7ms preprocess, 25.1ms inference, 0.0ms loss, 7.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n",
      "mAP50 for all classes is 0.822\n",
      "mAP50 for priority classes is 0.823\n",
      "mAP50 for lower-priority classes is 0.822\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gEfj9oyiWFv",
    "outputId": "18f8158d-5c0a-40d2-cb64-01be772f7016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.801      0.747      0.782      0.615\n",
      "           Articulated         68        113      0.702      0.813      0.758      0.581\n",
      "                   Bus         56         89      0.944      0.764      0.845      0.708\n",
      "                   Car        154       1251      0.859      0.901      0.929      0.622\n",
      "                 Coach         24         29      0.868      0.759      0.781      0.672\n",
      "                   LGV        180        273      0.816      0.747      0.794      0.612\n",
      "          Rigid 2 Axle        123        168      0.823      0.666       0.78      0.572\n",
      "          Rigid 3 Axle         17         17      0.456      0.445      0.474      0.417\n",
      "          Rigid 4 Axle         41         42      0.947      0.976      0.976      0.798\n",
      "                  Taxi         20         29      0.789      0.655      0.701      0.556\n",
      "Speed: 0.7ms preprocess, 25.3ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val8\u001b[0m\n",
      "mAP50 for all classes is 0.782\n",
      "mAP50 for priority classes is 0.756\n",
      "mAP50 for lower-priority classes is 0.803\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCe3Erm7iVf2",
    "outputId": "e68024b5-92fd-4ce2-e5ab-299fa7df81e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.569      0.638      0.648      0.432\n",
      "           Articulated         68        113      0.492      0.752      0.705      0.449\n",
      "                   Bus         56         89      0.702      0.661      0.687      0.504\n",
      "                   Car        154       1251      0.669      0.915      0.889      0.523\n",
      "                 Coach         24         29       0.55      0.552      0.513      0.378\n",
      "                   LGV        180        273      0.507      0.751      0.718      0.463\n",
      "          Rigid 2 Axle        123        168      0.567      0.589      0.594       0.37\n",
      "          Rigid 3 Axle         17         17      0.655      0.412      0.554      0.404\n",
      "          Rigid 4 Axle         41         42      0.617       0.73      0.828      0.566\n",
      "                  Taxi         20         29      0.358      0.379       0.34      0.234\n",
      "Speed: 0.7ms preprocess, 25.7ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n",
      "mAP50 for all classes is 0.648\n",
      "mAP50 for priority classes is 0.673\n",
      "mAP50 for lower-priority classes is 0.627\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgkALaXBiTKC"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSEIdXvZiW7u",
    "outputId": "af258a56-cf05-4f4a-ab8d-564e5aa5143e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.745      0.613      0.714      0.532\n",
      "           Articulated         68        113      0.691      0.699      0.773      0.575\n",
      "                   Bus         56         89      0.877      0.708      0.797      0.651\n",
      "                   Car        154       1251      0.825      0.899      0.912      0.596\n",
      "                 Coach         24         29      0.828      0.448      0.563      0.507\n",
      "                   LGV        180        273      0.709      0.696      0.759      0.556\n",
      "          Rigid 2 Axle        123        168      0.807      0.458      0.683      0.484\n",
      "          Rigid 3 Axle         17         17      0.641      0.294      0.524      0.413\n",
      "          Rigid 4 Axle         41         42      0.684      0.881      0.865      0.689\n",
      "                  Taxi         20         29      0.643      0.435       0.55      0.312\n",
      "Speed: 0.7ms preprocess, 25.6ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n",
      "mAP50 for all classes is 0.714\n",
      "mAP50 for priority classes is 0.708\n",
      "mAP50 for lower-priority classes is 0.719\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVJ_oJDxiWzO",
    "outputId": "33f6eaed-bd1f-4edf-9f6e-b26e0016272e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.691      0.678      0.732       0.56\n",
      "           Articulated         68        113      0.725      0.735      0.795      0.608\n",
      "                   Bus         56         89      0.857      0.775       0.84      0.699\n",
      "                   Car        154       1251      0.864      0.888      0.923      0.608\n",
      "                 Coach         24         29      0.758      0.552      0.681      0.584\n",
      "                   LGV        180        273      0.638      0.777      0.781      0.578\n",
      "          Rigid 2 Axle        123        168      0.769      0.494      0.691      0.497\n",
      "          Rigid 3 Axle         17         17      0.252      0.529      0.512      0.427\n",
      "          Rigid 4 Axle         41         42      0.683      0.857      0.829      0.687\n",
      "                  Taxi         20         29      0.671      0.493      0.538      0.351\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 8.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val11\u001b[0m\n",
      "mAP50 for all classes is 0.732\n",
      "mAP50 for priority classes is 0.703\n",
      "mAP50 for lower-priority classes is 0.756\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4r4nw5lSiWnK",
    "outputId": "e58cb0c9-9d24-4de6-f238-579c471a25d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.524       0.48      0.423      0.214\n",
      "           Articulated         68        113      0.444      0.478      0.432      0.223\n",
      "                   Bus         56         89      0.697      0.621      0.672       0.36\n",
      "                   Car        154       1251      0.656      0.886      0.846      0.405\n",
      "                 Coach         24         29      0.329      0.345      0.218     0.0922\n",
      "                   LGV        180        273      0.449      0.575      0.461      0.227\n",
      "          Rigid 2 Axle        123        168      0.432      0.405      0.393      0.192\n",
      "          Rigid 3 Axle         17         17      0.281      0.412      0.237      0.146\n",
      "          Rigid 4 Axle         41         42      0.428      0.595      0.482       0.24\n",
      "                  Taxi         20         29          1          0     0.0642      0.036\n",
      "Speed: 0.8ms preprocess, 25.4ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val13\u001b[0m\n",
      "mAP50 for all classes is 0.423\n",
      "mAP50 for priority classes is 0.393\n",
      "mAP50 for lower-priority classes is 0.446\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.01/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLEO9cO6fdmn"
   },
   "source": [
    "#### Learning Rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioXrRCo5jVbf"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4U00mGhGjd34",
    "outputId": "28076b93-0b6b-4da1-8ac7-ff3042f49c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.827      0.756      0.817      0.652\n",
      "           Articulated         68        113      0.851      0.823      0.895      0.731\n",
      "                   Bus         56         89      0.882      0.831      0.896      0.764\n",
      "                   Car        154       1251      0.887      0.876      0.939      0.639\n",
      "                 Coach         24         29      0.906      0.663      0.718      0.627\n",
      "                   LGV        180        273      0.853      0.763      0.844      0.653\n",
      "          Rigid 2 Axle        123        168      0.799      0.685       0.83      0.629\n",
      "          Rigid 3 Axle         17         17      0.646      0.529      0.543      0.474\n",
      "          Rigid 4 Axle         41         42      0.904      0.976      0.973      0.825\n",
      "                  Taxi         20         29      0.719      0.655      0.718      0.525\n",
      "Speed: 0.7ms preprocess, 24.4ms inference, 0.0ms loss, 8.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n",
      "mAP50 for all classes is 0.817\n",
      "mAP50 for priority classes is 0.797\n",
      "mAP50 for lower-priority classes is 0.833\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOyV_1adjdvU",
    "outputId": "708cf117-b252-4f4c-e9bc-513ed82777bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.882      0.729      0.821      0.651\n",
      "           Articulated         68        113      0.835      0.807      0.879      0.707\n",
      "                   Bus         56         89      0.916       0.82      0.892      0.778\n",
      "                   Car        154       1251      0.917      0.847      0.932      0.631\n",
      "                 Coach         24         29      0.903      0.644      0.763      0.673\n",
      "                   LGV        180        273       0.87      0.718      0.842      0.645\n",
      "          Rigid 2 Axle        123        168      0.855      0.631      0.795      0.601\n",
      "          Rigid 3 Axle         17         17      0.733      0.588      0.656      0.572\n",
      "          Rigid 4 Axle         41         42       0.97      0.952      0.971      0.796\n",
      "                  Taxi         20         29      0.941      0.551      0.658      0.456\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 8.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n",
      "mAP50 for all classes is 0.821\n",
      "mAP50 for priority classes is 0.816\n",
      "mAP50 for lower-priority classes is 0.825\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v59CEKTejdeC",
    "outputId": "a5e6b489-4928-47ad-de7f-9e99ecf7526c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.691      0.526      0.597      0.397\n",
      "           Articulated         68        113      0.472      0.779      0.713      0.486\n",
      "                   Bus         56         89       0.76      0.745      0.772      0.598\n",
      "                   Car        154       1251      0.766      0.894      0.895      0.506\n",
      "                 Coach         24         29          1      0.131      0.413      0.328\n",
      "                   LGV        180        273       0.52       0.77      0.718      0.445\n",
      "          Rigid 2 Axle        123        168      0.525      0.454      0.502      0.307\n",
      "          Rigid 3 Axle         17         17      0.594      0.353      0.497      0.364\n",
      "          Rigid 4 Axle         41         42      0.579      0.556      0.657      0.402\n",
      "                  Taxi         20         29          1     0.0543      0.209      0.136\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n",
      "mAP50 for all classes is 0.597\n",
      "mAP50 for priority classes is 0.593\n",
      "mAP50 for lower-priority classes is 0.6\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDgULgHdjVxw"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKX8X0O4jeqZ",
    "outputId": "3138ceeb-08db-488a-e9f0-44ec22317af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.878      0.727      0.836      0.669\n",
      "           Articulated         68        113       0.83      0.788      0.895      0.733\n",
      "                   Bus         56         89      0.924       0.82       0.91      0.789\n",
      "                   Car        154       1251       0.92      0.828      0.938      0.639\n",
      "                 Coach         24         29      0.949      0.641      0.774      0.677\n",
      "                   LGV        180        273      0.885      0.733      0.851      0.661\n",
      "          Rigid 2 Axle        123        168      0.848      0.643      0.819      0.629\n",
      "          Rigid 3 Axle         17         17      0.759      0.529      0.652      0.563\n",
      "          Rigid 4 Axle         41         42      0.953      0.905       0.97      0.815\n",
      "                  Taxi         20         29      0.834      0.655      0.713      0.513\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 8.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val17\u001b[0m\n",
      "mAP50 for all classes is 0.836\n",
      "mAP50 for priority classes is 0.823\n",
      "mAP50 for lower-priority classes is 0.846\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7I2jN7Tjekf",
    "outputId": "63072775-bf3f-41eb-cf78-8dc908010440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.852      0.731      0.807       0.64\n",
      "           Articulated         68        113      0.807      0.813      0.876      0.708\n",
      "                   Bus         56         89      0.903      0.809      0.887      0.772\n",
      "                   Car        154       1251      0.903       0.86      0.926      0.629\n",
      "                 Coach         24         29      0.907      0.676      0.781      0.675\n",
      "                   LGV        180        273      0.826      0.748      0.841      0.642\n",
      "          Rigid 2 Axle        123        168      0.846      0.623      0.783       0.59\n",
      "          Rigid 3 Axle         17         17      0.694      0.529      0.554      0.489\n",
      "          Rigid 4 Axle         41         42      0.929      0.941      0.957      0.789\n",
      "                  Taxi         20         29      0.849       0.58       0.66       0.47\n",
      "Speed: 0.7ms preprocess, 24.7ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val18\u001b[0m\n",
      "mAP50 for all classes is 0.807\n",
      "mAP50 for priority classes is 0.784\n",
      "mAP50 for lower-priority classes is 0.826\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7kN10AXjecR",
    "outputId": "d42a742f-ef88-4635-8b14-a04193dc54df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.674      0.536      0.606      0.413\n",
      "           Articulated         68        113      0.473      0.779      0.701      0.488\n",
      "                   Bus         56         89      0.759      0.764      0.792      0.613\n",
      "                   Car        154       1251      0.767       0.89      0.896      0.514\n",
      "                 Coach         24         29      0.754      0.138      0.493      0.407\n",
      "                   LGV        180        273      0.524      0.747      0.708      0.448\n",
      "          Rigid 2 Axle        123        168      0.513       0.47      0.506      0.318\n",
      "          Rigid 3 Axle         17         17      0.674      0.353        0.5       0.38\n",
      "          Rigid 4 Axle         41         42      0.605      0.619      0.654      0.418\n",
      "                  Taxi         20         29          1     0.0631      0.203      0.132\n",
      "Speed: 0.7ms preprocess, 24.4ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
      "mAP50 for all classes is 0.606\n",
      "mAP50 for priority classes is 0.592\n",
      "mAP50 for lower-priority classes is 0.617\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnOOrrv_jWHY"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYHz_HFHjfYX",
    "outputId": "0381c968-95d4-44cc-976d-6a39c0e0decf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.848      0.757      0.837      0.673\n",
      "           Articulated         68        113      0.805      0.823      0.897      0.733\n",
      "                   Bus         56         89      0.884      0.809      0.908      0.791\n",
      "                   Car        154       1251      0.886      0.889      0.942       0.64\n",
      "                 Coach         24         29      0.906      0.666       0.82      0.723\n",
      "                   LGV        180        273      0.859      0.769      0.851      0.655\n",
      "          Rigid 2 Axle        123        168      0.784      0.692      0.821       0.63\n",
      "          Rigid 3 Axle         17         17      0.832      0.581      0.627      0.541\n",
      "          Rigid 4 Axle         41         42       0.89      0.966      0.969      0.825\n",
      "                  Taxi         20         29      0.788      0.621      0.695      0.516\n",
      "Speed: 0.7ms preprocess, 24.4ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n",
      "mAP50 for all classes is 0.837\n",
      "mAP50 for priority classes is 0.817\n",
      "mAP50 for lower-priority classes is 0.853\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQntvCfcjfQR",
    "outputId": "7e5d6f4a-45bb-4117-88a5-f53842daca0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.832       0.77      0.827      0.658\n",
      "           Articulated         68        113      0.791       0.85      0.883      0.716\n",
      "                   Bus         56         89      0.918      0.843        0.9       0.77\n",
      "                   Car        154       1251      0.855       0.91      0.938      0.634\n",
      "                 Coach         24         29          1      0.688      0.823      0.711\n",
      "                   LGV        180        273      0.816      0.791      0.856      0.663\n",
      "          Rigid 2 Axle        123        168      0.768      0.691      0.786        0.6\n",
      "          Rigid 3 Axle         17         17      0.611      0.588      0.607       0.54\n",
      "          Rigid 4 Axle         41         42       0.91      0.958      0.975      0.792\n",
      "                  Taxi         20         29      0.816      0.613      0.675      0.494\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val21\u001b[0m\n",
      "mAP50 for all classes is 0.827\n",
      "mAP50 for priority classes is 0.806\n",
      "mAP50 for lower-priority classes is 0.844\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7QnRxyRffe1",
    "outputId": "0d7454da-c0ef-4daa-f51a-8cf5dbb98ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.643       0.54      0.599      0.406\n",
      "           Articulated         68        113      0.491       0.77      0.693      0.479\n",
      "                   Bus         56         89      0.741      0.738      0.789      0.621\n",
      "                   Car        154       1251      0.755      0.905      0.896      0.511\n",
      "                 Coach         24         29      0.791      0.207      0.449      0.358\n",
      "                   LGV        180        273      0.525      0.758      0.716      0.446\n",
      "          Rigid 2 Axle        123        168      0.548      0.494      0.522      0.335\n",
      "          Rigid 3 Axle         17         17      0.874      0.409      0.518       0.38\n",
      "          Rigid 4 Axle         41         42      0.568      0.548      0.666      0.429\n",
      "                  Taxi         20         29       0.49     0.0345      0.142     0.0992\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
      "mAP50 for all classes is 0.599\n",
      "mAP50 for priority classes is 0.606\n",
      "mAP50 for lower-priority classes is 0.594\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.001/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeVIdpIcffy8"
   },
   "source": [
    "#### Learning Rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkGAYV4ZkgWR"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUc2YBQwklCh",
    "outputId": "453bbfb7-be1a-4bfc-f107-7177bc87dfc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.699      0.586      0.687      0.527\n",
      "           Articulated         68        113      0.632      0.788      0.792      0.607\n",
      "                   Bus         56         89      0.789      0.843       0.88      0.731\n",
      "                   Car        154       1251      0.815      0.913      0.925      0.604\n",
      "                 Coach         24         29        0.8      0.276      0.623      0.547\n",
      "                   LGV        180        273       0.68      0.747      0.783      0.595\n",
      "          Rigid 2 Axle        123        168      0.669      0.554      0.678        0.5\n",
      "          Rigid 3 Axle         17         17      0.614      0.412      0.483      0.401\n",
      "          Rigid 4 Axle         41         42      0.701       0.67      0.798      0.616\n",
      "                  Taxi         20         29      0.591      0.069      0.219      0.141\n",
      "Speed: 0.8ms preprocess, 25.3ms inference, 0.0ms loss, 7.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val23\u001b[0m\n",
      "mAP50 for all classes is 0.687\n",
      "mAP50 for priority classes is 0.686\n",
      "mAP50 for lower-priority classes is 0.688\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VaobE_Wkk9D",
    "outputId": "6de02a40-6a13-45a3-f8c7-f98b44d526e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.648       0.64      0.698      0.542\n",
      "           Articulated         68        113      0.624      0.796      0.782      0.606\n",
      "                   Bus         56         89      0.818      0.876      0.893      0.741\n",
      "                   Car        154       1251      0.814      0.921      0.931      0.612\n",
      "                 Coach         24         29      0.875      0.483      0.683      0.601\n",
      "                   LGV        180        273      0.662      0.783      0.802      0.609\n",
      "          Rigid 2 Axle        123        168      0.622      0.577      0.679        0.5\n",
      "          Rigid 3 Axle         17         17       0.45      0.529      0.521      0.438\n",
      "          Rigid 4 Axle         41         42      0.637       0.69      0.771      0.622\n",
      "                  Taxi         20         29      0.326      0.103      0.221      0.145\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val24\u001b[0m\n",
      "mAP50 for all classes is 0.698\n",
      "mAP50 for priority classes is 0.693\n",
      "mAP50 for lower-priority classes is 0.702\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqDdfKYzkk1w",
    "outputId": "eaabe18f-acee-4028-ce45-479162f25d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011       0.53      0.384      0.362      0.202\n",
      "           Articulated         68        113      0.314      0.354      0.293      0.175\n",
      "                   Bus         56         89      0.702      0.685      0.706      0.471\n",
      "                   Car        154       1251      0.637      0.889      0.832      0.399\n",
      "                 Coach         24         29          1          0      0.147      0.101\n",
      "                   LGV        180        273      0.397      0.608      0.458      0.234\n",
      "          Rigid 2 Axle        123        168      0.362       0.47      0.349      0.199\n",
      "          Rigid 3 Axle         17         17          0          0      0.118     0.0743\n",
      "          Rigid 4 Axle         41         42      0.357      0.452      0.306      0.139\n",
      "                  Taxi         20         29          1          0     0.0453     0.0277\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 8.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val25\u001b[0m\n",
      "mAP50 for all classes is 0.362\n",
      "mAP50 for priority classes is 0.308\n",
      "mAP50 for lower-priority classes is 0.404\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITpYuEhSkh6s"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzHvHDqgklvu",
    "outputId": "155d2bff-5d54-4761-e331-acd95b4ef500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.731      0.559      0.682      0.526\n",
      "           Articulated         68        113       0.65      0.761      0.771      0.591\n",
      "                   Bus         56         89      0.814      0.831      0.878      0.733\n",
      "                   Car        154       1251       0.84      0.893      0.926      0.605\n",
      "                 Coach         24         29      0.887       0.27      0.651      0.573\n",
      "                   LGV        180        273      0.718      0.714      0.784      0.598\n",
      "          Rigid 2 Axle        123        168      0.717      0.494      0.682      0.507\n",
      "          Rigid 3 Axle         17         17      0.629      0.353      0.457      0.386\n",
      "          Rigid 4 Axle         41         42      0.702      0.643      0.771      0.594\n",
      "                  Taxi         20         29      0.622      0.069      0.217      0.144\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 8.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val26\u001b[0m\n",
      "mAP50 for all classes is 0.682\n",
      "mAP50 for priority classes is 0.674\n",
      "mAP50 for lower-priority classes is 0.688\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lm10kVQklr-",
    "outputId": "7ffc052b-360d-49be-d73d-5f4c78f38cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.651       0.63      0.694      0.538\n",
      "           Articulated         68        113      0.596      0.788      0.788      0.609\n",
      "                   Bus         56         89      0.826      0.876      0.893      0.735\n",
      "                   Car        154       1251       0.81      0.927       0.93      0.612\n",
      "                 Coach         24         29      0.859      0.422      0.684      0.605\n",
      "                   LGV        180        273      0.658      0.795      0.805      0.612\n",
      "          Rigid 2 Axle        123        168      0.609      0.577      0.675      0.499\n",
      "          Rigid 3 Axle         17         17      0.423      0.471      0.501      0.421\n",
      "          Rigid 4 Axle         41         42      0.614      0.714      0.755      0.609\n",
      "                  Taxi         20         29       0.46      0.103      0.218      0.144\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val27\u001b[0m\n",
      "mAP50 for all classes is 0.694\n",
      "mAP50 for priority classes is 0.684\n",
      "mAP50 for lower-priority classes is 0.703\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVyNpURWkln3",
    "outputId": "218deb2b-eb0e-4f63-ed2a-10f780888528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.532       0.39      0.361      0.202\n",
      "           Articulated         68        113      0.304      0.359      0.293      0.175\n",
      "                   Bus         56         89       0.72      0.694      0.701      0.466\n",
      "                   Car        154       1251      0.634      0.886       0.83        0.4\n",
      "                 Coach         24         29          1          0      0.145     0.0966\n",
      "                   LGV        180        273        0.4      0.623       0.46      0.234\n",
      "          Rigid 2 Axle        123        168      0.355       0.47      0.359      0.208\n",
      "          Rigid 3 Axle         17         17          0          0      0.121     0.0759\n",
      "          Rigid 4 Axle         41         42       0.37      0.476      0.297      0.135\n",
      "                  Taxi         20         29          1          0     0.0422     0.0257\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 8.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val28\u001b[0m\n",
      "mAP50 for all classes is 0.361\n",
      "mAP50 for priority classes is 0.309\n",
      "mAP50 for lower-priority classes is 0.402\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RxAy9JwkjYa"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thAjy3kWfhVk",
    "outputId": "fd5c1ab5-2673-4804-e39e-ddbfc85c7e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.641      0.636      0.689       0.53\n",
      "           Articulated         68        113      0.586      0.828      0.777      0.597\n",
      "                   Bus         56         89      0.747      0.854      0.881      0.734\n",
      "                   Car        154       1251      0.772      0.941      0.926      0.604\n",
      "                 Coach         24         29      0.851      0.394       0.65      0.574\n",
      "                   LGV        180        273      0.625      0.776      0.782      0.596\n",
      "          Rigid 2 Axle        123        168       0.62      0.661      0.679      0.504\n",
      "          Rigid 3 Axle         17         17      0.413      0.412      0.486      0.397\n",
      "          Rigid 4 Axle         41         42      0.647      0.786       0.79      0.612\n",
      "                  Taxi         20         29      0.509      0.069      0.233      0.151\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val29\u001b[0m\n",
      "mAP50 for all classes is 0.689\n",
      "mAP50 for priority classes is 0.684\n",
      "mAP50 for lower-priority classes is 0.693\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJaCxOqPkmmB",
    "outputId": "d9234c7b-7f03-42c7-949e-0add9f46f7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.664      0.642      0.698       0.54\n",
      "           Articulated         68        113      0.621      0.788      0.779      0.605\n",
      "                   Bus         56         89      0.821      0.876      0.895      0.734\n",
      "                   Car        154       1251      0.816      0.926      0.931      0.613\n",
      "                 Coach         24         29      0.825      0.486      0.687      0.608\n",
      "                   LGV        180        273      0.665      0.791      0.805       0.61\n",
      "          Rigid 2 Axle        123        168       0.63      0.577      0.683      0.506\n",
      "          Rigid 3 Axle         17         17      0.489      0.529       0.51      0.428\n",
      "          Rigid 4 Axle         41         42      0.649      0.705      0.771      0.615\n",
      "                  Taxi         20         29      0.458      0.103      0.222      0.145\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val30\u001b[0m\n",
      "mAP50 for all classes is 0.698\n",
      "mAP50 for priority classes is 0.692\n",
      "mAP50 for lower-priority classes is 0.703\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkEWIVOPkmSa",
    "outputId": "c41bb4bb-b125-4799-b9bf-510df3850106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Model summary (fused): 268 layers, 68,132,235 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:14<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.649      0.388      0.367      0.206\n",
      "           Articulated         68        113      0.312      0.345      0.298       0.18\n",
      "                   Bus         56         89      0.715      0.685      0.703      0.468\n",
      "                   Car        154       1251      0.643      0.885      0.831        0.4\n",
      "                 Coach         24         29          1          0      0.171      0.121\n",
      "                   LGV        180        273      0.395      0.608      0.459      0.235\n",
      "          Rigid 2 Axle        123        168      0.363      0.464      0.355      0.204\n",
      "          Rigid 3 Axle         17         17          1          0      0.111     0.0717\n",
      "          Rigid 4 Axle         41         42      0.413        0.5       0.33      0.151\n",
      "                  Taxi         20         29          1          0     0.0459     0.0279\n",
      "Speed: 0.7ms preprocess, 24.6ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val31\u001b[0m\n",
      "mAP50 for all classes is 0.367\n",
      "mAP50 for priority classes is 0.314\n",
      "mAP50 for lower-priority classes is 0.41\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv8/lr_0.0001/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
