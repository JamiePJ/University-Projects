{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtBoroqIfKLv"
   },
   "source": [
    "## Validation of YOLOv10x GridSearch Models\n",
    "#### File Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7SvgqqSfICB"
   },
   "outputs": [],
   "source": [
    "# function for calculating mAP50 for all classes, priority classes and lower-priority classes\n",
    "def calc_map50_class_groups(metrics_object):\n",
    "    priority_classes = [metrics_object.box.ap50[4], metrics_object.box.ap50[5], metrics_object.box.ap50[6], metrics_object.box.ap50[7]]\n",
    "    lower_priority_classes = [metrics_object.box.ap50[2], metrics_object.box.ap50[8], metrics_object.box.ap50[1],\n",
    "                              metrics_object.box.ap50[3], metrics_object.box.ap50[0]]\n",
    "    priority_class_map50 = round(sum(priority_classes)/len(priority_classes),3)\n",
    "    lower_priority_class_map50 = round(sum(lower_priority_classes)/len(lower_priority_classes),3)\n",
    "    print(f\"mAP50 for all classes is {round(metrics.box.map50,3)}\")\n",
    "    print(f\"mAP50 for priority classes is {priority_class_map50}\")\n",
    "    print(f\"mAP50 for lower-priority classes is {lower_priority_class_map50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmJw6w_Le6w2"
   },
   "outputs": [],
   "source": [
    "# solves occasional error with Linux commands and encoding\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjuAv6ELe8Up",
    "outputId": "7901fed8-e50a-4069-fe87-d4645dd7cd27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive for saving runs and model files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYchVPa7e90U",
    "outputId": "8fd84c1a-4f09-4e88-a53f-71132feccf85"
   },
   "outputs": [],
   "source": [
    "# copy dataset from google drive\n",
    "!unzip /content/drive/MyDrive/UniStuff/Dissertation/Dataset_zips/WSP-9.zip -d /content/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfAH7c_NfAin",
    "outputId": "4929f26b-e402-43ef-bed4-c90e4633b2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "Setup complete ‚úÖ (12 CPUs, 53.0 GB RAM, 35.9/78.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# install and import ultralytics\n",
    "\n",
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbZ1awbIfPtU"
   },
   "source": [
    "### Validation\n",
    "#### Learning Rate = 0.1\n",
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCPujpwqfZv_",
    "outputId": "dec23f14-1420-4626-c08e-15e970ff22a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 104MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<00:00, 1310.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/WSP-9/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.749      0.715      0.774      0.592\n",
      "           Articulated         68        113      0.788      0.821      0.862      0.652\n",
      "                   Bus         56         89      0.891      0.764      0.854      0.702\n",
      "                   Car        154       1251      0.843      0.903      0.932      0.617\n",
      "                 Coach         24         29      0.946      0.608      0.728      0.617\n",
      "                   LGV        180        273      0.783      0.768      0.817      0.617\n",
      "          Rigid 2 Axle        123        168      0.723      0.643      0.747      0.543\n",
      "          Rigid 3 Axle         17         17       0.37      0.346      0.475      0.391\n",
      "          Rigid 4 Axle         41         42      0.722      0.929      0.878      0.705\n",
      "                  Taxi         20         29       0.67      0.655      0.674      0.484\n",
      "Speed: 0.7ms preprocess, 31.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "mAP50 for all classes is 0.774\n",
      "mAP50 for priority classes is 0.729\n",
      "mAP50 for lower-priority classes is 0.81\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Guz38Zauf-FW",
    "outputId": "dd32216b-6b44-4d20-d3b3-8f0ff6d37074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.747      0.662      0.736      0.555\n",
      "           Articulated         68        113      0.743      0.664      0.772      0.574\n",
      "                   Bus         56         89      0.782      0.742      0.804      0.633\n",
      "                   Car        154       1251      0.851      0.883      0.923      0.603\n",
      "                 Coach         24         29      0.802      0.586      0.678      0.584\n",
      "                   LGV        180        273      0.762      0.722      0.761      0.559\n",
      "          Rigid 2 Axle        123        168      0.764       0.53      0.689      0.488\n",
      "          Rigid 3 Axle         17         17      0.443      0.412      0.478      0.391\n",
      "          Rigid 4 Axle         41         42      0.807      0.905      0.875      0.704\n",
      "                  Taxi         20         29      0.767      0.517      0.645      0.458\n",
      "Speed: 0.7ms preprocess, 29.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "mAP50 for all classes is 0.736\n",
      "mAP50 for priority classes is 0.701\n",
      "mAP50 for lower-priority classes is 0.765\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8OVqsaAf-ZB",
    "outputId": "8afe6ff0-28d6-49f2-9835-6b606764a566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.445      0.421      0.392      0.216\n",
      "           Articulated         68        113      0.376      0.416      0.364      0.173\n",
      "                   Bus         56         89      0.422      0.528      0.443       0.27\n",
      "                   Car        154       1251      0.544      0.864      0.802      0.424\n",
      "                 Coach         24         29      0.287      0.172      0.139     0.0694\n",
      "                   LGV        180        273      0.334      0.591      0.459      0.258\n",
      "          Rigid 2 Axle        123        168      0.327      0.339      0.301       0.14\n",
      "          Rigid 3 Axle         17         17      0.891      0.294       0.41       0.27\n",
      "          Rigid 4 Axle         41         42      0.523      0.548       0.48      0.257\n",
      "                  Taxi         20         29      0.302     0.0345       0.13     0.0797\n",
      "Speed: 0.7ms preprocess, 28.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "mAP50 for all classes is 0.392\n",
      "mAP50 for priority classes is 0.412\n",
      "mAP50 for lower-priority classes is 0.376\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywviOVwflQ9"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ix80uszufnIY",
    "outputId": "d3d2a22d-53de-4d15-d855-92bf38ca0210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.689      0.535      0.616      0.436\n",
      "           Articulated         68        113      0.705       0.55      0.684      0.474\n",
      "                   Bus         56         89      0.839      0.618      0.709       0.54\n",
      "                   Car        154       1251      0.799      0.879      0.899      0.574\n",
      "                 Coach         24         29      0.483      0.414       0.43      0.345\n",
      "                   LGV        180        273      0.646      0.641      0.685      0.489\n",
      "          Rigid 2 Axle        123        168      0.707      0.359      0.548      0.373\n",
      "          Rigid 3 Axle         17         17      0.792      0.294      0.391      0.303\n",
      "          Rigid 4 Axle         41         42      0.655      0.738      0.766      0.559\n",
      "                  Taxi         20         29      0.572      0.324       0.43      0.269\n",
      "Speed: 0.7ms preprocess, 26.8ms inference, 0.1ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "mAP50 for all classes is 0.616\n",
      "mAP50 for priority classes is 0.597\n",
      "mAP50 for lower-priority classes is 0.63\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frTVFnKEg-s0",
    "outputId": "59572abb-05e3-4aeb-e220-579d05b717c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.652      0.571      0.609      0.427\n",
      "           Articulated         68        113      0.797      0.556      0.673      0.458\n",
      "                   Bus         56         89      0.772      0.685      0.731      0.535\n",
      "                   Car        154       1251      0.806      0.886      0.902      0.574\n",
      "                 Coach         24         29      0.485      0.621      0.541      0.404\n",
      "                   LGV        180        273      0.633      0.669      0.654      0.446\n",
      "          Rigid 2 Axle        123        168      0.695      0.369      0.527      0.345\n",
      "          Rigid 3 Axle         17         17      0.492      0.294      0.356      0.285\n",
      "          Rigid 4 Axle         41         42      0.618      0.833      0.782      0.581\n",
      "                  Taxi         20         29      0.569      0.229       0.31      0.217\n",
      "Speed: 0.7ms preprocess, 29.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
      "mAP50 for all classes is 0.609\n",
      "mAP50 for priority classes is 0.58\n",
      "mAP50 for lower-priority classes is 0.631\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYKKpm6sg--W",
    "outputId": "fa031219-9f89-4881-9364-18198387692f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  30%|‚ñà‚ñà‚ñà       | 7/23 [00:05<00:11,  1.37it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e7c91e62d40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14/23 [00:09<00:04,  2.09it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e7c91e62d40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21/23 [00:12<00:00,  2.14it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e7c91e62d40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.561      0.209      0.182     0.0726\n",
      "           Articulated         68        113      0.528     0.0354     0.0821     0.0352\n",
      "                   Bus         56         89      0.278      0.292       0.14     0.0684\n",
      "                   Car        154       1251      0.397       0.75       0.65      0.265\n",
      "                 Coach         24         29          1          0     0.0363     0.0116\n",
      "                   LGV        180        273       0.24      0.407      0.268      0.117\n",
      "          Rigid 2 Axle        123        168      0.255      0.113      0.134     0.0495\n",
      "          Rigid 3 Axle         17         17          1          0     0.0105    0.00481\n",
      "          Rigid 4 Axle         41         42      0.353      0.286        0.3     0.0921\n",
      "                  Taxi         20         29          1          0     0.0207    0.00939\n",
      "Speed: 0.7ms preprocess, 31.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
      "mAP50 for all classes is 0.182\n",
      "mAP50 for priority classes is 0.178\n",
      "mAP50 for lower-priority classes is 0.186\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-qvWlrJfm3L"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQBMB8BDfqGE",
    "outputId": "db338ad9-63ba-4556-849a-5d6820c7913a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:12<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.352      0.161      0.112     0.0634\n",
      "           Articulated         68        113      0.112     0.0265     0.0448     0.0223\n",
      "                   Bus         56         89      0.292      0.124      0.117     0.0644\n",
      "                   Car        154       1251      0.367      0.752      0.556      0.317\n",
      "                 Coach         24         29          0          0     0.0274     0.0185\n",
      "                   LGV        180        273      0.176      0.307      0.135     0.0765\n",
      "          Rigid 2 Axle        123        168      0.167      0.101     0.0816     0.0418\n",
      "          Rigid 3 Axle         17         17          1          0    0.00574    0.00256\n",
      "          Rigid 4 Axle         41         42     0.0539      0.143     0.0327     0.0199\n",
      "                  Taxi         20         29          1          0      0.011    0.00711\n",
      "Speed: 0.7ms preprocess, 27.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n",
      "mAP50 for all classes is 0.112\n",
      "mAP50 for priority classes is 0.064\n",
      "mAP50 for lower-priority classes is 0.151\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OM4zLxyIhC21",
    "outputId": "b20d9dde-05bb-40c1-db85-c0c558fbfc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.441      0.181      0.168      0.097\n",
      "           Articulated         68        113       0.35     0.0796      0.102     0.0552\n",
      "                   Bus         56         89      0.284       0.27      0.174     0.0868\n",
      "                   Car        154       1251       0.44      0.757      0.647      0.376\n",
      "                 Coach         24         29     0.0722     0.0345     0.0403     0.0229\n",
      "                   LGV        180        273      0.189       0.33       0.25      0.145\n",
      "          Rigid 2 Axle        123        168      0.151      0.036     0.0959     0.0499\n",
      "          Rigid 3 Axle         17         17          1          0     0.0191     0.0107\n",
      "          Rigid 4 Axle         41         42      0.484      0.119      0.171      0.116\n",
      "                  Taxi         20         29          1          0     0.0153    0.00957\n",
      "Speed: 0.7ms preprocess, 29.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val8\u001b[0m\n",
      "mAP50 for all classes is 0.168\n",
      "mAP50 for priority classes is 0.134\n",
      "mAP50 for lower-priority classes is 0.196\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Th3Au-UEhDGZ",
    "outputId": "d395f392-8699-4134-b18e-cae6a76938b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:12<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.446    0.00559    0.00103   0.000288\n",
      "           Articulated         68        113          1          0          0          0\n",
      "                   Bus         56         89          0          0    0.00397   0.000891\n",
      "                   Car        154       1251    0.00595      0.032    0.00354    0.00123\n",
      "                 Coach         24         29          1          0          0          0\n",
      "                   LGV        180        273    0.00729     0.0183    0.00172   0.000465\n",
      "          Rigid 2 Axle        123        168          1          0          0          0\n",
      "          Rigid 3 Axle         17         17          1          0          0          0\n",
      "          Rigid 4 Axle         41         42          0          0          0          0\n",
      "                  Taxi         20         29          0          0          0          0\n",
      "Speed: 0.8ms preprocess, 26.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n",
      "mAP50 for all classes is 0.001\n",
      "mAP50 for priority classes is 0.0\n",
      "mAP50 for lower-priority classes is 0.002\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.1/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkiaJx2JfaML"
   },
   "source": [
    "#### Learning Rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aisTf3CniPlh"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQpv8zBXfDBs",
    "outputId": "d75f62ec-6fe7-480b-c3f4-7a217c8745c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.823      0.716        0.8      0.628\n",
      "           Articulated         68        113       0.81      0.791      0.862      0.677\n",
      "                   Bus         56         89       0.91      0.794      0.885      0.745\n",
      "                   Car        154       1251      0.876      0.897      0.936      0.632\n",
      "                 Coach         24         29      0.946      0.601      0.745      0.652\n",
      "                   LGV        180        273      0.825      0.733      0.841      0.636\n",
      "          Rigid 2 Axle        123        168      0.838      0.555      0.786      0.574\n",
      "          Rigid 3 Axle         17         17      0.441      0.588      0.487      0.402\n",
      "          Rigid 4 Axle         41         42      0.883      0.901      0.931      0.781\n",
      "                  Taxi         20         29      0.881      0.586      0.725      0.552\n",
      "Speed: 0.7ms preprocess, 25.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n",
      "mAP50 for all classes is 0.8\n",
      "mAP50 for priority classes is 0.761\n",
      "mAP50 for lower-priority classes is 0.83\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78QUSyiziU4P",
    "outputId": "87afeac9-ea09-4ab1-831a-e1867801d5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011       0.85      0.706      0.812      0.643\n",
      "           Articulated         68        113      0.815       0.74       0.84       0.65\n",
      "                   Bus         56         89        0.9      0.719       0.86      0.713\n",
      "                   Car        154       1251       0.88      0.862      0.924      0.619\n",
      "                 Coach         24         29      0.948      0.635      0.808      0.714\n",
      "                   LGV        180        273      0.807      0.765      0.805      0.612\n",
      "          Rigid 2 Axle        123        168      0.855      0.554      0.773      0.579\n",
      "          Rigid 3 Axle         17         17      0.588      0.471      0.587      0.509\n",
      "          Rigid 4 Axle         41         42      0.953      0.972      0.971      0.832\n",
      "                  Taxi         20         29      0.902      0.636      0.743      0.557\n",
      "Speed: 0.7ms preprocess, 28.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val11\u001b[0m\n",
      "mAP50 for all classes is 0.812\n",
      "mAP50 for priority classes is 0.784\n",
      "mAP50 for lower-priority classes is 0.835\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6efVqPSpiVIt",
    "outputId": "59034da3-cfa0-479b-d158-35b470ad4148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.624      0.578      0.655      0.444\n",
      "           Articulated         68        113      0.581      0.708       0.68      0.455\n",
      "                   Bus         56         89      0.741      0.674      0.745      0.529\n",
      "                   Car        154       1251      0.779      0.866      0.895      0.536\n",
      "                 Coach         24         29      0.575      0.483      0.568      0.403\n",
      "                   LGV        180        273      0.657      0.681      0.729      0.491\n",
      "          Rigid 2 Axle        123        168      0.657      0.434      0.603      0.372\n",
      "          Rigid 3 Axle         17         17      0.605      0.361      0.545      0.413\n",
      "          Rigid 4 Axle         41         42      0.676      0.786      0.823      0.577\n",
      "                  Taxi         20         29      0.342      0.207      0.308      0.217\n",
      "Speed: 0.7ms preprocess, 30.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n",
      "mAP50 for all classes is 0.655\n",
      "mAP50 for priority classes is 0.675\n",
      "mAP50 for lower-priority classes is 0.639\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfyCsO-2iRvJ"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkMjXULViUm1",
    "outputId": "bf0db02f-d828-4f31-deb4-461baea2cfeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.814      0.721      0.794      0.619\n",
      "           Articulated         68        113        0.8       0.78      0.847      0.657\n",
      "                   Bus         56         89       0.84      0.767      0.849      0.695\n",
      "                   Car        154       1251      0.873      0.873       0.93      0.622\n",
      "                 Coach         24         29      0.925      0.586      0.717      0.634\n",
      "                   LGV        180        273      0.775      0.732      0.794      0.615\n",
      "          Rigid 2 Axle        123        168       0.87      0.598      0.795      0.571\n",
      "          Rigid 3 Axle         17         17      0.505      0.588      0.535       0.47\n",
      "          Rigid 4 Axle         41         42      0.875      0.929       0.94      0.776\n",
      "                  Taxi         20         29       0.86      0.638      0.736      0.528\n",
      "Speed: 0.7ms preprocess, 29.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val13\u001b[0m\n",
      "mAP50 for all classes is 0.794\n",
      "mAP50 for priority classes is 0.766\n",
      "mAP50 for lower-priority classes is 0.816\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gEfj9oyiWFv",
    "outputId": "32cc2132-6e7c-405b-94b4-35308cc59b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.829      0.715      0.783      0.609\n",
      "           Articulated         68        113      0.858      0.697      0.814      0.635\n",
      "                   Bus         56         89      0.886      0.789      0.873       0.69\n",
      "                   Car        154       1251      0.872      0.878      0.915      0.608\n",
      "                 Coach         24         29          1       0.65      0.783      0.655\n",
      "                   LGV        180        273      0.798       0.74      0.797      0.607\n",
      "          Rigid 2 Axle        123        168      0.784      0.589      0.743      0.538\n",
      "          Rigid 3 Axle         17         17      0.412      0.529      0.432      0.368\n",
      "          Rigid 4 Axle         41         42      0.907      0.952      0.973      0.815\n",
      "                  Taxi         20         29      0.946      0.605       0.72      0.567\n",
      "Speed: 0.8ms preprocess, 26.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n",
      "mAP50 for all classes is 0.783\n",
      "mAP50 for priority classes is 0.736\n",
      "mAP50 for lower-priority classes is 0.821\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCe3Erm7iVf2",
    "outputId": "1abee2dc-b4a7-4108-d813-d0998610636d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.588      0.557      0.598      0.395\n",
      "           Articulated         68        113       0.62      0.606      0.673      0.445\n",
      "                   Bus         56         89      0.658      0.652       0.69      0.482\n",
      "                   Car        154       1251      0.713       0.89      0.887      0.518\n",
      "                 Coach         24         29       0.53      0.414      0.402      0.289\n",
      "                   LGV        180        273      0.524      0.678      0.655      0.449\n",
      "          Rigid 2 Axle        123        168      0.642      0.405      0.544      0.325\n",
      "          Rigid 3 Axle         17         17      0.638      0.294      0.454      0.344\n",
      "          Rigid 4 Axle         41         42      0.589      0.762      0.763      0.515\n",
      "                  Taxi         20         29      0.377       0.31      0.313      0.185\n",
      "Speed: 0.8ms preprocess, 25.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n",
      "mAP50 for all classes is 0.598\n",
      "mAP50 for priority classes is 0.604\n",
      "mAP50 for lower-priority classes is 0.593\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgkALaXBiTKC"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSEIdXvZiW7u",
    "outputId": "382286ce-bcd3-427f-adac-dc50c15f0ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.664      0.592      0.668      0.491\n",
      "           Articulated         68        113      0.817      0.611       0.74      0.548\n",
      "                   Bus         56         89      0.742      0.697      0.739        0.6\n",
      "                   Car        154       1251      0.771      0.911      0.917      0.586\n",
      "                 Coach         24         29      0.602      0.261       0.45      0.368\n",
      "                   LGV        180        273      0.604      0.769      0.737      0.547\n",
      "          Rigid 2 Axle        123        168      0.706      0.536      0.686      0.492\n",
      "          Rigid 3 Axle         17         17      0.491      0.353      0.483       0.38\n",
      "          Rigid 4 Axle         41         42       0.72      0.736      0.756      0.585\n",
      "                  Taxi         20         29      0.524      0.456      0.501       0.31\n",
      "Speed: 0.7ms preprocess, 30.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n",
      "mAP50 for all classes is 0.668\n",
      "mAP50 for priority classes is 0.665\n",
      "mAP50 for lower-priority classes is 0.669\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVJ_oJDxiWzO",
    "outputId": "95594b8f-3c89-482c-fe37-079a998be043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.662      0.631      0.692      0.526\n",
      "           Articulated         68        113      0.661      0.639      0.691      0.529\n",
      "                   Bus         56         89      0.809      0.761      0.806       0.67\n",
      "                   Car        154       1251      0.759       0.92      0.903       0.59\n",
      "                 Coach         24         29      0.879      0.483      0.627       0.56\n",
      "                   LGV        180        273       0.53      0.773      0.745      0.543\n",
      "          Rigid 2 Axle        123        168      0.707      0.603      0.688      0.472\n",
      "          Rigid 3 Axle         17         17      0.421      0.386      0.428      0.344\n",
      "          Rigid 4 Axle         41         42      0.547      0.864      0.801      0.657\n",
      "                  Taxi         20         29      0.641      0.247      0.537      0.374\n",
      "Speed: 0.8ms preprocess, 26.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val17\u001b[0m\n",
      "mAP50 for all classes is 0.692\n",
      "mAP50 for priority classes is 0.666\n",
      "mAP50 for lower-priority classes is 0.713\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4r4nw5lSiWnK",
    "outputId": "b9cb8138-3893-47d1-c155-29ce1ae32f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.468      0.417      0.347      0.141\n",
      "           Articulated         68        113       0.36       0.46      0.309      0.129\n",
      "                   Bus         56         89      0.668      0.475      0.517      0.217\n",
      "                   Car        154       1251      0.608       0.85      0.792      0.348\n",
      "                 Coach         24         29      0.255      0.172      0.205     0.0566\n",
      "                   LGV        180        273      0.394      0.619      0.422      0.181\n",
      "          Rigid 2 Axle        123        168      0.364      0.452      0.339      0.134\n",
      "          Rigid 3 Axle         17         17      0.202      0.176      0.132     0.0762\n",
      "          Rigid 4 Axle         41         42       0.36      0.548      0.348     0.0991\n",
      "                  Taxi         20         29          1          0      0.057     0.0319\n",
      "Speed: 0.7ms preprocess, 29.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val18\u001b[0m\n",
      "mAP50 for all classes is 0.347\n",
      "mAP50 for priority classes is 0.31\n",
      "mAP50 for lower-priority classes is 0.376\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.01/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLEO9cO6fdmn"
   },
   "source": [
    "#### Learning Rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioXrRCo5jVbf"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4U00mGhGjd34",
    "outputId": "9a792e3b-276a-4f90-81e5-816880a804eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.828      0.728      0.821      0.645\n",
      "           Articulated         68        113      0.842      0.804      0.881      0.714\n",
      "                   Bus         56         89      0.884      0.775      0.889      0.726\n",
      "                   Car        154       1251      0.899       0.86      0.945      0.636\n",
      "                 Coach         24         29      0.955      0.552      0.798      0.713\n",
      "                   LGV        180        273      0.843      0.769      0.859      0.661\n",
      "          Rigid 2 Axle        123        168      0.897      0.621      0.801      0.614\n",
      "          Rigid 3 Axle         17         17      0.432      0.588      0.556       0.47\n",
      "          Rigid 4 Axle         41         42      0.931      0.905      0.946      0.783\n",
      "                  Taxi         20         29      0.766      0.677       0.71      0.485\n",
      "Speed: 0.7ms preprocess, 27.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
      "mAP50 for all classes is 0.821\n",
      "mAP50 for priority classes is 0.79\n",
      "mAP50 for lower-priority classes is 0.845\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOyV_1adjdvU",
    "outputId": "61f73386-a305-49cb-ecde-ff09017e2421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.825      0.745      0.816      0.649\n",
      "           Articulated         68        113      0.861      0.814      0.893      0.717\n",
      "                   Bus         56         89       0.87      0.798      0.885      0.756\n",
      "                   Car        154       1251      0.886      0.893      0.939      0.639\n",
      "                 Coach         24         29      0.937      0.655      0.764      0.672\n",
      "                   LGV        180        273      0.834      0.766      0.859      0.661\n",
      "          Rigid 2 Axle        123        168      0.815      0.656      0.781      0.578\n",
      "          Rigid 3 Axle         17         17       0.52      0.588       0.58      0.518\n",
      "          Rigid 4 Axle         41         42      0.846      0.919      0.955      0.809\n",
      "                  Taxi         20         29      0.856      0.621      0.691      0.495\n",
      "Speed: 0.8ms preprocess, 25.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n",
      "mAP50 for all classes is 0.816\n",
      "mAP50 for priority classes is 0.794\n",
      "mAP50 for lower-priority classes is 0.834\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v59CEKTejdeC",
    "outputId": "1e823ac2-1649-480d-8668-64e473270ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.531      0.572      0.579      0.408\n",
      "           Articulated         68        113      0.553      0.712      0.695      0.473\n",
      "                   Bus         56         89       0.76      0.748      0.771      0.606\n",
      "                   Car        154       1251      0.702      0.908      0.897      0.545\n",
      "                 Coach         24         29      0.511      0.253      0.363      0.287\n",
      "                   LGV        180        273      0.482      0.747      0.676       0.48\n",
      "          Rigid 2 Axle        123        168      0.432      0.566      0.494      0.334\n",
      "          Rigid 3 Axle         17         17      0.405      0.442      0.472      0.346\n",
      "          Rigid 4 Axle         41         42      0.489      0.667      0.604      0.433\n",
      "                  Taxi         20         29      0.441      0.103      0.238      0.169\n",
      "Speed: 0.7ms preprocess, 31.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val21\u001b[0m\n",
      "mAP50 for all classes is 0.579\n",
      "mAP50 for priority classes is 0.562\n",
      "mAP50 for lower-priority classes is 0.593\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDgULgHdjVxw"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKX8X0O4jeqZ",
    "outputId": "42776fcf-92e7-439a-a511-7b47984b7617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.841      0.715      0.815      0.641\n",
      "           Articulated         68        113      0.859      0.752      0.871      0.703\n",
      "                   Bus         56         89      0.877      0.804      0.888       0.73\n",
      "                   Car        154       1251      0.905      0.859      0.947      0.643\n",
      "                 Coach         24         29       0.85      0.586      0.737      0.651\n",
      "                   LGV        180        273      0.858       0.74      0.843      0.647\n",
      "          Rigid 2 Axle        123        168      0.829      0.577      0.795      0.593\n",
      "          Rigid 3 Axle         17         17      0.675      0.471      0.566      0.489\n",
      "          Rigid 4 Axle         41         42      0.907      0.928      0.942      0.792\n",
      "                  Taxi         20         29      0.807      0.721      0.746      0.522\n",
      "Speed: 0.7ms preprocess, 30.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
      "mAP50 for all classes is 0.815\n",
      "mAP50 for priority classes is 0.786\n",
      "mAP50 for lower-priority classes is 0.838\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7I2jN7Tjekf",
    "outputId": "468a8089-8402-4d23-d312-58eda9704be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.828      0.738      0.812      0.646\n",
      "           Articulated         68        113      0.831      0.832      0.884      0.706\n",
      "                   Bus         56         89      0.888      0.804      0.886      0.761\n",
      "                   Car        154       1251      0.887      0.885      0.939      0.636\n",
      "                 Coach         24         29      0.945      0.589      0.752       0.66\n",
      "                   LGV        180        273      0.828      0.762      0.859      0.664\n",
      "          Rigid 2 Axle        123        168      0.835      0.603      0.798      0.587\n",
      "          Rigid 3 Axle         17         17      0.469      0.588      0.535      0.463\n",
      "          Rigid 4 Axle         41         42      0.866      0.924      0.939      0.808\n",
      "                  Taxi         20         29        0.9      0.655      0.718      0.531\n",
      "Speed: 0.8ms preprocess, 26.6ms inference, 0.1ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val23\u001b[0m\n",
      "mAP50 for all classes is 0.812\n",
      "mAP50 for priority classes is 0.783\n",
      "mAP50 for lower-priority classes is 0.836\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7kN10AXjecR",
    "outputId": "c663268b-ca93-415e-dcf7-91c7f5c74e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.671      0.497       0.57      0.404\n",
      "           Articulated         68        113      0.614      0.611       0.67      0.458\n",
      "                   Bus         56         89       0.81      0.717      0.768      0.602\n",
      "                   Car        154       1251      0.738       0.88      0.893      0.547\n",
      "                 Coach         24         29      0.706      0.166      0.325       0.26\n",
      "                   LGV        180        273      0.567       0.69      0.676      0.484\n",
      "          Rigid 2 Axle        123        168       0.52      0.504      0.506      0.342\n",
      "          Rigid 3 Axle         17         17      0.607      0.353      0.477      0.375\n",
      "          Rigid 4 Axle         41         42      0.645       0.52      0.582      0.408\n",
      "                  Taxi         20         29      0.831     0.0345      0.236      0.163\n",
      "Speed: 0.7ms preprocess, 28.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val24\u001b[0m\n",
      "mAP50 for all classes is 0.57\n",
      "mAP50 for priority classes is 0.56\n",
      "mAP50 for lower-priority classes is 0.578\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnOOrrv_jWHY"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYHz_HFHjfYX",
    "outputId": "b9265a62-bf6e-4255-fbe4-d3a55c8d18e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011       0.86      0.736      0.826      0.647\n",
      "           Articulated         68        113      0.813      0.823      0.867      0.681\n",
      "                   Bus         56         89      0.848      0.843       0.87      0.737\n",
      "                   Car        154       1251      0.883      0.883      0.942      0.639\n",
      "                 Coach         24         29      0.919      0.586      0.781      0.689\n",
      "                   LGV        180        273      0.848       0.78      0.861      0.653\n",
      "          Rigid 2 Axle        123        168      0.804       0.66      0.805      0.599\n",
      "          Rigid 3 Axle         17         17          1      0.501      0.633      0.523\n",
      "          Rigid 4 Axle         41         42      0.846      0.952      0.944      0.783\n",
      "                  Taxi         20         29      0.776      0.597      0.726      0.519\n",
      "Speed: 0.7ms preprocess, 26.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val25\u001b[0m\n",
      "mAP50 for all classes is 0.826\n",
      "mAP50 for priority classes is 0.811\n",
      "mAP50 for lower-priority classes is 0.837\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQntvCfcjfQR",
    "outputId": "2f2a817e-f48c-4398-b75e-1fe98789beb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.834      0.749      0.817      0.647\n",
      "           Articulated         68        113      0.819      0.842      0.881      0.692\n",
      "                   Bus         56         89      0.924      0.815      0.911      0.766\n",
      "                   Car        154       1251      0.872      0.893      0.935      0.636\n",
      "                 Coach         24         29          1       0.68      0.804      0.696\n",
      "                   LGV        180        273      0.831      0.751      0.843      0.649\n",
      "          Rigid 2 Axle        123        168      0.818      0.619      0.777      0.583\n",
      "          Rigid 3 Axle         17         17      0.558      0.529      0.528      0.429\n",
      "          Rigid 4 Axle         41         42      0.853      0.929      0.963      0.817\n",
      "                  Taxi         20         29      0.831       0.68      0.707      0.555\n",
      "Speed: 0.8ms preprocess, 26.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val26\u001b[0m\n",
      "mAP50 for all classes is 0.817\n",
      "mAP50 for priority classes is 0.778\n",
      "mAP50 for lower-priority classes is 0.848\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7QnRxyRffe1",
    "outputId": "876c128f-1bc3-4c2c-ee0c-d0bbb819713c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.521      0.527      0.546      0.382\n",
      "           Articulated         68        113      0.567      0.575      0.627      0.422\n",
      "                   Bus         56         89       0.75      0.663      0.723      0.545\n",
      "                   Car        154       1251      0.699       0.91      0.894      0.553\n",
      "                 Coach         24         29      0.287       0.31      0.319      0.252\n",
      "                   LGV        180        273      0.525      0.733      0.659      0.468\n",
      "          Rigid 2 Axle        123        168      0.507      0.483      0.495      0.324\n",
      "          Rigid 3 Axle         17         17      0.411      0.412      0.404      0.305\n",
      "          Rigid 4 Axle         41         42      0.515      0.548      0.505      0.361\n",
      "                  Taxi         20         29      0.432      0.105      0.291      0.205\n",
      "Speed: 0.7ms preprocess, 27.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val27\u001b[0m\n",
      "mAP50 for all classes is 0.546\n",
      "mAP50 for priority classes is 0.515\n",
      "mAP50 for lower-priority classes is 0.571\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.001/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeVIdpIcffy8"
   },
   "source": [
    "#### Learning Rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkGAYV4ZkgWR"
   },
   "source": [
    "Weight decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUc2YBQwklCh",
    "outputId": "170ac04b-1e8d-453b-e812-e5189c9c4aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.522      0.626      0.617      0.476\n",
      "           Articulated         68        113      0.528      0.811      0.755      0.567\n",
      "                   Bus         56         89      0.723      0.843      0.875      0.737\n",
      "                   Car        154       1251      0.676      0.954       0.92      0.601\n",
      "                 Coach         24         29      0.849       0.39      0.576      0.531\n",
      "                   LGV        180        273      0.562      0.813       0.76      0.578\n",
      "          Rigid 2 Axle        123        168      0.457      0.679      0.588      0.422\n",
      "          Rigid 3 Axle         17         17      0.173      0.118      0.233      0.193\n",
      "          Rigid 4 Axle         41         42      0.353      0.714      0.567      0.463\n",
      "                  Taxi         20         29      0.372       0.31      0.284      0.189\n",
      "Speed: 0.7ms preprocess, 30.5ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val28\u001b[0m\n",
      "mAP50 for all classes is 0.617\n",
      "mAP50 for priority classes is 0.537\n",
      "mAP50 for lower-priority classes is 0.682\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.0005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VaobE_Wkk9D",
    "outputId": "d9b765dd-e659-4cc1-e8e6-0694e4522ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.692      0.572       0.65      0.501\n",
      "           Articulated         68        113      0.662      0.735      0.774      0.581\n",
      "                   Bus         56         89      0.842      0.831      0.883      0.742\n",
      "                   Car        154       1251      0.798      0.919      0.931      0.614\n",
      "                 Coach         24         29      0.805      0.429      0.666      0.604\n",
      "                   LGV        180        273      0.701      0.769      0.773      0.582\n",
      "          Rigid 2 Axle        123        168      0.531      0.512      0.573      0.413\n",
      "          Rigid 3 Axle         17         17      0.811      0.294      0.407      0.337\n",
      "          Rigid 4 Axle         41         42      0.478      0.452      0.555      0.442\n",
      "                  Taxi         20         29      0.601      0.207      0.288      0.196\n",
      "Speed: 0.8ms preprocess, 28.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val29\u001b[0m\n",
      "mAP50 for all classes is 0.65\n",
      "mAP50 for priority classes is 0.577\n",
      "mAP50 for lower-priority classes is 0.708\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.0005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqDdfKYzkk1w",
    "outputId": "b48a341a-a421-43eb-e4c5-27e4611e7b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.458      0.426      0.372      0.215\n",
      "           Articulated         68        113      0.254      0.283        0.2      0.119\n",
      "                   Bus         56         89       0.56      0.663      0.643      0.432\n",
      "                   Car        154       1251      0.526      0.918      0.826      0.392\n",
      "                 Coach         24         29      0.343      0.207      0.288      0.187\n",
      "                   LGV        180        273      0.254      0.736       0.47      0.238\n",
      "          Rigid 2 Axle        123        168      0.283      0.495       0.27      0.148\n",
      "          Rigid 3 Axle         17         17      0.609      0.118      0.275      0.189\n",
      "          Rigid 4 Axle         41         42      0.294      0.418       0.28      0.159\n",
      "                  Taxi         20         29          1          0      0.092     0.0663\n",
      "Speed: 0.7ms preprocess, 27.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val30\u001b[0m\n",
      "mAP50 for all classes is 0.372\n",
      "mAP50 for priority classes is 0.324\n",
      "mAP50 for lower-priority classes is 0.41\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.0005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITpYuEhSkh6s"
   },
   "source": [
    "Weight decay = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzHvHDqgklvu",
    "outputId": "02d70f30-2a90-4ca6-89ed-4b8e147a6b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.545      0.607      0.621      0.478\n",
      "           Articulated         68        113      0.563      0.779      0.757      0.563\n",
      "                   Bus         56         89      0.762      0.843      0.873      0.729\n",
      "                   Car        154       1251      0.693       0.95      0.922      0.602\n",
      "                 Coach         24         29      0.775      0.357      0.599       0.55\n",
      "                   LGV        180        273      0.586        0.8      0.765      0.583\n",
      "          Rigid 2 Axle        123        168      0.469      0.643       0.58      0.419\n",
      "          Rigid 3 Axle         17         17       0.27      0.118      0.246      0.204\n",
      "          Rigid 4 Axle         41         42      0.363      0.714      0.566      0.461\n",
      "                  Taxi         20         29      0.427      0.257      0.282      0.189\n",
      "Speed: 0.8ms preprocess, 25.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val31\u001b[0m\n",
      "mAP50 for all classes is 0.621\n",
      "mAP50 for priority classes is 0.539\n",
      "mAP50 for lower-priority classes is 0.687\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.005/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lm10kVQklr-",
    "outputId": "87ac5315-7437-4e36-d1d1-36c8064a8126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.636      0.604       0.65      0.503\n",
      "           Articulated         68        113      0.624       0.77      0.795      0.598\n",
      "                   Bus         56         89      0.817      0.831      0.881      0.743\n",
      "                   Car        154       1251      0.768      0.934      0.929      0.614\n",
      "                 Coach         24         29      0.934      0.485      0.704      0.639\n",
      "                   LGV        180        273      0.663      0.791      0.778      0.588\n",
      "          Rigid 2 Axle        123        168       0.52      0.554       0.58      0.416\n",
      "          Rigid 3 Axle         17         17      0.344      0.353      0.303       0.25\n",
      "          Rigid 4 Axle         41         42      0.418      0.476      0.546      0.447\n",
      "                  Taxi         20         29      0.638      0.241      0.332      0.228\n",
      "Speed: 0.7ms preprocess, 29.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val32\u001b[0m\n",
      "mAP50 for all classes is 0.65\n",
      "mAP50 for priority classes is 0.552\n",
      "mAP50 for lower-priority classes is 0.728\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.005/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVyNpURWkln3",
    "outputId": "27eabefe-b7e4-43ac-b21d-b794c33047ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.473       0.43      0.368      0.213\n",
      "           Articulated         68        113      0.295      0.319      0.208      0.126\n",
      "                   Bus         56         89      0.549      0.663      0.638       0.43\n",
      "                   Car        154       1251      0.528      0.912      0.828      0.395\n",
      "                 Coach         24         29      0.361      0.207      0.286      0.187\n",
      "                   LGV        180        273      0.252      0.733      0.469       0.24\n",
      "          Rigid 2 Axle        123        168      0.307        0.5      0.273      0.152\n",
      "          Rigid 3 Axle         17         17      0.655      0.114      0.248      0.168\n",
      "          Rigid 4 Axle         41         42      0.314      0.425      0.289      0.167\n",
      "                  Taxi         20         29          1          0      0.071     0.0507\n",
      "Speed: 0.8ms preprocess, 28.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val33\u001b[0m\n",
      "mAP50 for all classes is 0.368\n",
      "mAP50 for priority classes is 0.32\n",
      "mAP50 for lower-priority classes is 0.406\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.005/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RxAy9JwkjYa"
   },
   "source": [
    "Weight decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thAjy3kWfhVk",
    "outputId": "27dd12e3-91bd-4899-ea4a-c10e60a56e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.619      0.578      0.624       0.48\n",
      "           Articulated         68        113      0.615      0.743      0.787      0.586\n",
      "                   Bus         56         89      0.817      0.843      0.878      0.736\n",
      "                   Car        154       1251      0.716      0.942       0.92      0.601\n",
      "                 Coach         24         29      0.878      0.345      0.597      0.554\n",
      "                   LGV        180        273      0.635      0.788      0.761      0.576\n",
      "          Rigid 2 Axle        123        168      0.499      0.592      0.569      0.409\n",
      "          Rigid 3 Axle         17         17      0.539      0.118       0.28      0.231\n",
      "          Rigid 4 Axle         41         42      0.371      0.595      0.548       0.44\n",
      "                  Taxi         20         29      0.503      0.241      0.273      0.183\n",
      "Speed: 0.7ms preprocess, 28.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val34\u001b[0m\n",
      "mAP50 for all classes is 0.624\n",
      "mAP50 for priority classes is 0.54\n",
      "mAP50 for lower-priority classes is 0.691\n"
     ]
    }
   ],
   "source": [
    "# default augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.05/augment_default/weights/best.pt\")\n",
    "metrics = model.val(data=\"/content/datasets/WSP-9/data.yaml\")\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJaCxOqPkmmB",
    "outputId": "b8e1e87e-6754-4c0a-bab1-14c7ff970744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:14<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011       0.67      0.583      0.663      0.512\n",
      "           Articulated         68        113      0.633      0.761      0.787      0.589\n",
      "                   Bus         56         89      0.834       0.82       0.88      0.738\n",
      "                   Car        154       1251      0.792      0.925      0.932      0.616\n",
      "                 Coach         24         29      0.928      0.446      0.688      0.637\n",
      "                   LGV        180        273      0.678      0.777      0.778      0.583\n",
      "          Rigid 2 Axle        123        168      0.532      0.508      0.587      0.426\n",
      "          Rigid 3 Axle         17         17      0.462      0.294      0.415      0.343\n",
      "          Rigid 4 Axle         41         42      0.437      0.476      0.545       0.43\n",
      "                  Taxi         20         29      0.731      0.241      0.354      0.247\n",
      "Speed: 0.8ms preprocess, 30.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val35\u001b[0m\n",
      "mAP50 for all classes is 0.663\n",
      "mAP50 for priority classes is 0.581\n",
      "mAP50 for lower-priority classes is 0.728\n"
     ]
    }
   ],
   "source": [
    "# decreased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.05/augment_min/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkEWIVOPkmSa",
    "outputId": "22dcdd61-e10c-4a5d-c275-814a4c6e461b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.77 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
      "YOLOv10x summary (fused): 503 layers, 31,601,414 parameters, 0 gradients, 169.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/WSP-9/valid/labels.cache... 359 images, 14 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        359       2011      0.445      0.446      0.378      0.219\n",
      "           Articulated         68        113       0.28      0.327      0.226      0.139\n",
      "                   Bus         56         89      0.549      0.674       0.64      0.433\n",
      "                   Car        154       1251      0.516      0.919      0.824      0.393\n",
      "                 Coach         24         29      0.343      0.207      0.269      0.181\n",
      "                   LGV        180        273      0.244      0.744      0.458      0.235\n",
      "          Rigid 2 Axle        123        168      0.289      0.512      0.275      0.154\n",
      "          Rigid 3 Axle         17         17      0.473      0.176        0.3      0.199\n",
      "          Rigid 4 Axle         41         42       0.31      0.452      0.312      0.174\n",
      "                  Taxi         20         29          1          0     0.0939     0.0678\n",
      "Speed: 0.7ms preprocess, 28.9ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val36\u001b[0m\n",
      "mAP50 for all classes is 0.378\n",
      "mAP50 for priority classes is 0.336\n",
      "mAP50 for lower-priority classes is 0.411\n"
     ]
    }
   ],
   "source": [
    "# increased augmentation\n",
    "model = YOLO(\"/content/drive/MyDrive/UniStuff/Dissertation/ModelRuns/GridSearch/YOLOv10/lr_0.0001/weight_decay_0.05/augment_increase/weights/best.pt\")\n",
    "metrics = model.val()\n",
    "calc_map50_class_groups(metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
